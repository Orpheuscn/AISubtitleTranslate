# DeepSeek API Token 使用量分析报告

## 📊 基础信息

### DeepSeek API 限制
- **输入限制**: 32,000 tokens
- **输出限制**: 8,000 tokens
- **总上下文窗口**: 32,000 tokens

### 系统提示词（固定部分）
- **字符数**: 1,643
- **中文字符**: 848
- **英文单词**: 35
- **估算 Tokens**: **~1,758 tokens**

## 📈 不同批次大小的 Token 使用量

| 批次大小 | System Tokens | User Tokens | 总 Tokens | 使用率 | 剩余空间 | 状态 |
|---------|--------------|-------------|----------|--------|---------|------|
| 10 条   | 1,758        | 819         | 2,577    | 8.05%  | 29,423  | ✅ 安全 |
| 20 条   | 1,758        | 1,019       | 2,777    | 8.68%  | 29,223  | ✅ 安全 |
| 30 条   | 1,758        | 1,219       | 2,977    | 9.30%  | 29,023  | ✅ 安全 |
| **50 条**   | **1,758**        | **1,619**       | **3,377**    | **10.55%** | **28,623**  | **✅ 推荐** |
| 100 条  | 1,758        | 2,625       | 4,383    | 13.70% | 27,617  | ✅ 安全 |
| 150 条  | 1,758        | 3,655       | 5,413    | 16.92% | 26,587  | ✅ 安全 |
| 200 条  | 1,758        | 4,685       | 6,443    | 20.13% | 25,557  | ✅ 安全 |

*注：以上数据基于模拟字幕（每条约 10-15 个英文单词）*

## 🎯 实际字幕场景分析

### 场景 1: 短对话（平均每条 5-10 个单词）
- **推荐批次大小**: 100-150 条
- **预估 Token 使用**: 4,000-5,500 tokens
- **使用率**: 12-17%

### 场景 2: 正常对话（平均每条 10-15 个单词）
- **推荐批次大小**: 50-100 条
- **预估 Token 使用**: 3,400-4,400 tokens
- **使用率**: 10-14%
- **✅ 当前默认设置**

### 场景 3: 长对话/独白（平均每条 15-25 个单词）
- **推荐批次大小**: 30-50 条
- **预估 Token 使用**: 3,000-4,000 tokens
- **使用率**: 9-12%

### 场景 4: 极长字幕（平均每条 25+ 个单词）
- **推荐批次大小**: 20-30 条
- **预估 Token 使用**: 2,800-3,500 tokens
- **使用率**: 8-11%

## 💡 优化建议

### 1. 当前配置（50 条/批次）
```typescript
// src/composables/useSubtitleTranslation.ts
const batchSize = 50  // 当前设置
const contextSize = 5  // 前后上下文各 5 条
```

**优点**:
- ✅ Token 使用率仅 10.55%，非常安全
- ✅ 足够的上下文保证翻译连贯性
- ✅ 适合大多数电影字幕场景

**缺点**:
- ⚠️ 对于短字幕可能效率较低
- ⚠️ 翻译时间较长（批次数量多）

### 2. 动态批次大小（推荐）
根据字幕平均长度动态调整：

```typescript
function calculateOptimalBatchSize(entries: SubtitleEntry[]): number {
  // 计算平均字幕长度
  const avgLength = entries.reduce((sum, e) => sum + e.text.length, 0) / entries.length
  
  if (avgLength < 30) {
    return 100  // 短字幕
  } else if (avgLength < 60) {
    return 50   // 正常字幕（当前默认）
  } else if (avgLength < 100) {
    return 30   // 长字幕
  } else {
    return 20   // 极长字幕
  }
}
```

### 3. Token 预算分配

假设使用 50 条/批次的配置：

| 组件 | Token 预算 | 占比 |
|------|-----------|------|
| System Prompt | 1,758 | 52% |
| User Message (字幕内容) | 1,619 | 48% |
| **输入总计** | **3,377** | **100%** |
| 输出（翻译结果） | ~2,000 | - |
| **总计** | **~5,377** | **16.8%** |

### 4. 安全边界

为了确保不超出限制，建议：

1. **保守估计**: 实际字幕可能比模拟数据更长
2. **缓冲空间**: 保留 20% 的缓冲（约 25,600 tokens）
3. **动态检测**: 在发送前检测 token 数量，超出则自动减少批次大小

## 🔍 术语词典的影响

当术语词典增长时，System Prompt 会变长：

| 术语数量 | 额外 Tokens | 总 System Tokens | 影响 |
|---------|------------|-----------------|------|
| 0 个    | 0          | 1,758           | 基准 |
| 10 个   | ~100       | 1,858           | +5.7% |
| 50 个   | ~500       | 2,258           | +28.4% |
| 100 个  | ~1,000     | 2,758           | +56.9% |
| 200 个  | ~2,000     | 3,758           | +113.8% |

**建议**:
- 当术语数量 > 100 时，考虑只传递相关术语（已实现）
- 当术语数量 > 200 时，考虑减少批次大小到 30-40 条

## 📝 实际测试建议

1. **监控实际使用量**: 在控制台查看每次请求的实际 token 数
2. **记录峰值**: 找出最长的批次，确保不超限
3. **调整策略**: 根据实际数据微调批次大小

## 🎬 结论

**当前配置（50 条/批次）非常合理**:
- ✅ Token 使用率仅 10.55%，远低于限制
- ✅ 即使字幕较长或术语较多，也有足够的缓冲空间
- ✅ 可以安全地处理大多数电影字幕场景

**如果需要提高效率**:
- 可以尝试增加到 100 条/批次（使用率 13.70%）
- 但要注意监控实际使用量，避免超限

**如果遇到超长字幕**:
- 可以临时减少到 30 条/批次（使用率 9.30%）
- 或实现动态批次大小调整

